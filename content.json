[{"title":"【ElasticStack】ElasticSearch聚合分析与数据建模","date":"2019-11-21T14:30:47.000Z","path":"article/20191121.html","text":"1. ElasticSearch中的聚合分析聚合分析，英文Aggregation，是ES除了搜索功能之外提供的针对ES数据进行统计分析的功能。 特点： ①功能丰富，可满足大部分分析需求； ②实时性高，所有计算结果实时返回。 基于分析规则的不同，ES将聚合分析主要划分为以下4种： Metric: 指标分析类型，如：计算最值，平均值等； Bucket: 分桶类型，类似于group by语法，根据一定规则划分为若干个桶分类； Pipeline: 管道分析类型，基于上一级的聚合分析结果进行再分析； Matrix: 矩阵分析类型。 1// 聚合分析格式：2GET my_index/_search3&#123;4 \"size\":0,5 \"aggs\":&#123; // 关键词6 \"&lt;aggregation_name&gt;\":&#123; // 自定义聚合分析名称，一般起的有意义7 \"&lt;aggregation_type&gt;\":&#123; // 聚合分析类型8 \"&lt;aggregation_body&gt;\" // 聚合分析主体9 &#125;10 &#125;11 [,\"aggs\":&#123;[&lt;svb_aggregation&gt;]+&#125;] // 可包含多个子聚合分析12 &#125;13&#125; 1.1 Metric聚合分析主要分为两类：单值分析（输出单个结果）和多值分析（输出多个结果）。 1.1.1 单值分析 min：返回数值类型字段的最小值 max：返回数值类型字段的最大值 avg：返回数值类型字段的平均值 sum：返回数值类型字段值的总和 cardinality：返回字段的基数 使用多个单值分析关键词，返回多个结果 1GET my_index/_search2&#123;3 \"size\": 0,4 \"aggs\":&#123;5 \"min_age\":&#123;6 \"min\":&#123; // 关键字min/max/avg/sum/cardinality7 \"field\":\"age\" 8 &#125;9 &#125;10 &#125;11&#125;12//13// 使用多个单值分析关键词，返回多个分析结果14GET my_index/_search15&#123;16 \"size\": 0,17 \"aggs\": &#123;18 \"min_age\":&#123;19 \"min\":&#123; // 求最小年龄20 \"field\":\"age\"21 &#125;22 &#125;,23 \"max_age\":&#123;24 \"max\":&#123; // 求最大年龄25 \"field\":\"age\"26 &#125;27 &#125;,28 \"avg_age\":&#123;29 \"avg\":&#123; // 求平均年龄30 \"field\":\"age\"31 &#125;32 &#125;,33 \"sum_age\":&#123;34 \"sum\":&#123; // 求年龄总和35 \"field\":\"age\"36 &#125;37 &#125;38 &#125;39&#125; 1.1.2 多值分析 stats：返回所有单值结果 extended_stats：对stats进行扩展，包含更多，如：方差，标准差，标准差范围等 Percentile：百分位数统计 Top hits：一般用于分桶之后获取该桶内最匹配的定不稳当列表，即详情数据 1GET my_index/_search2&#123;3 \"size\": 0,4 \"aggs\":&#123;5 \"stats_age\":&#123;6 \"stats\":&#123; // 关键字stats/extended_stats/percentiles7 \"field\":\"age\" 8 &#125;9 &#125;10 &#125;11&#125;12//13// 使用percentiles关键词进行百分位数预测。14GET my_index/_search15&#123;16 \"size\": 0,17 \"aggs\":&#123;18 \"per_age\":&#123;19 \"percentiles\":&#123; // 关键字20 \"field\":\"age\",21 \"values\":[20, 25] // 判断20和25分别在之前的年轻区间的什么位置，以百分数显示22 &#125;23 &#125;24 &#125;25&#125;26//27// 使用top_hits关键词28GET my_index/_search29&#123;30 \"size\":0,31 \"aggs\":&#123;32 \"jobs\":&#123;33 \"terms\":&#123;34 \"match\":&#123;35 \"field\":\"job.keyword\", // 按job.keyword进行分桶聚合36 \"size\":1037 &#125;,38 \"aggs\":&#123;39 \"top_employee\":&#123;40 \"top_hits\":&#123;41 \"size\":10, // 返回文档数量42 \"sort\":[43 &#123;44 \"age\":&#123;45 \"order\":\"desc\" // 按年龄倒叙排列46 &#125; 47 &#125;48 ]49 &#125;50 &#125;51 &#125;52 &#125;53 &#125;54 &#125;55&#125; 1.2 Bucket聚合分析Bucket，意为桶。即：按照一定规则，将文档分配到不同的桶中，达分类的目的。常见的有以下五类： Terms: 直接按term进行分桶，如果是text类型，按分词后的结果分桶 Range: 按指定数值范围进行分桶 Date Range: 按指定日期范围进行分桶 Histogram: 直方图，按固定数值间隔策略进行数据分割 Date Histogram: 日期直方图，按固定时间间隔进行数据分割 1.2.1 TermsTerms: 直接按term进行分桶，如果是text类型，按分词后的结果分桶 1// 使用terms关键词2GET my_index/_search3&#123;4 \"size\": 0,5 \"aggs\":&#123;6 \"terms_job\":&#123;7 \"terms\":&#123; // 关键字8 \"field\":\"job.keyword\", // 按job.keyword进行分桶9 \"size\":5 // 返回五个文档10 &#125;11 &#125;12 &#125;13&#125; 1.2.2 RangeRange: 按指定数值范围进行分桶： 1// 使用range关键词2GET my_index/_search3&#123;4 \"size\": 0,5 \"aggs\":&#123;6 \"number_ranges\":&#123;7 \"range\":&#123; // 关键字8 \"field\":\"age\", // 按age进行分桶9 \"ranges\":[10 &#123;11 \"key\":\"&gt;=19 &amp;&amp; &lt; 25\", // 第一个桶： 19&lt;=年龄&lt;2512 \"from\":19,13 \"to\":2514 &#125;,15 &#123;16 \"key\":\"&lt; 19\", // 第二个桶： 年龄&lt;1917 \"to\":1918 &#125;,19 &#123;20 \"key\":\"&gt;= 25\", // 第三个桶： 年龄&gt;=2521 \"from\":2522 &#125;23 ]24 &#125;25 &#125;26 &#125;27&#125; 1.2.2 Date RangeDate Range: 按指定日期范围进行分桶 1 3）：23// 使用date_range关键词4GET my_index/_search5&#123;6 \"size\": 0,7 \"aggs\":&#123;8 \"date_ranges\":&#123;9 \"date_range\":&#123; // 关键字10 \"field\":\"birth\", // 按age进行分桶11 \"format\":\"yyyy\",12 \"ranges\":[13 &#123;14 \"key\":\"&gt;=1980 &amp;&amp; &lt; 1990\", // 第一个桶： 1980&lt;=出生日期&lt;199015 \"from\":\"1980\",16 \"to\":\"1990\"17 &#125;,18 &#123;19 \"key\":\"&lt; 1980\", // 第二个桶： 出生日期&lt;198020 \"to\":198021 &#125;,22 &#123;23 \"key\":\"&gt;= 1990\", // 第三个桶： 出生日期&gt;=199024 \"from\":199025 &#125;26 ]27 &#125;28 &#125;29 &#125;30&#125; 1.2.2 HistogramHistogram: 直方图，按固定数值间隔策略进行数据分割 1// 使用histogram关键词2GET my_index/_search3&#123;4 \"size\": 0,5 \"aggs\":&#123;6 \"age_hist\":&#123;7 \"histogram\":&#123; // 关键词8 \"field\":\"age\",9 \"interval\":3, // 设定间隔大小为210 \"extended_bounds\":&#123; // 设定数据范围11 \"min\":0,12 \"max\":3013 &#125;14 &#125;15 &#125;16 &#125;17&#125; 1.2.2 Date HistogramDate Histogram: 日期直方图，按固定时间间隔进行数据分割 1// 使用date_histogram关键词2GET my_index/_search3&#123;4 \"size\": 0,5 \"aggs\":&#123;6 \"birth_hist\":&#123;7 \"date_histogram\":&#123; // 关键词8 \"field\":\"birth\",9 \"interval\":\"year\", // 设定间隔大小为年year10 \"format\":\"yyyy\",11 \"extended_bounds\":&#123; // 设定数据范围12 \"min\":\"1980\",13 \"max\":\"1990\"14 &#125;15 &#125;16 &#125;17 &#125;18&#125; 1.3 Bucket+Metric聚合分析Bucket聚合分析允许通过添加子分析来进一步进行分析，该子分析可以是Bucket，也可以是Metric。 分桶之后再分桶（Bucket+Bucket），在数据可视化中一般使用千层饼图进行显示。 分桶之后再数据分析（Bucket+Metric） 1// 分桶之后再分桶——Bucket+Bucket2GET my_index/_search3&#123;4 \"size\":0,5 \"aggs\":&#123;6 \"jobs\":&#123;7 \"terms\":&#123; // 第一层Bucket8 \"match\":&#123;9 \"field\":\"job.keyword\",10 \"size\":1011 &#125;,12 \"aggs\":&#123;13 \"age_range\":&#123;14 \"range\":&#123; // 第二层Bucket15 \"field\":\"age\",16 \"ranges\":[17 &#123;\"to\":20&#125;,18 &#123;\"from\":20,\"to\":30&#125;,19 &#123;\"from\":30&#125;20 ]21 &#125;22 &#125;23 &#125;24 &#125;25 &#125;26 &#125;27&#125; 1// 分桶之后再数据分析——Bucket+Metric2GET my_index/_search3&#123;4 \"size\":0,5 \"aggs\":&#123;6 \"jobs\":&#123;7 \"terms\":&#123; // 第一层Bucket8 \"match\":&#123;9 \"field\":\"job.keyword\",10 \"size\":1011 &#125;,12 \"aggs\":&#123; 13 \"stats_age\":&#123;14 \"stats\":&#123; // 第二层Metric15 \"field\":\"age\"16 &#125;17 &#125;18 &#125;19 &#125;20 &#125;21 &#125;22&#125; 1.4 Pipeline聚合分析针对聚合分析的结果进行再分析，且支持链式调用： 1// 使用pipeline聚合分析,计算订单月平均销售额。2GET my_index/_search3&#123;4 \"size\": 0,5 \"aggs\":&#123;6 \"sales_per_month\":&#123;7 \"date_histogram\":&#123;8 \"field\":\"date\",9 \"interval\":\"month\"10 &#125;,11 \"aggs\":&#123;12 \"sales\":&#123;13 \"sum\":&#123;14 \"field\":\"price\"15 &#125;16 &#125;17 &#125;18 &#125;,19 \"avg_monthly_sales\":&#123;20 \"avg_bucket\":&#123; // bucket类型21 \"buckets_path\":\"sales_per_month&gt;sales\" // 使用buckets_path参数，表明是pipeline22 &#125;23 &#125;24 &#125;25&#125; pipeline的分析结果会输出到原结果中，由输出位置不同，分为两类：Parent和Sibling。 Sibling。结果与现有聚合分析结果同级，如：Max/Min/Sum/Avg Bucket、Stats/Extended Stats Bucket、Percentiles Bucket Parent。结果内嵌到现有聚合分析结果中，如：Derivate、Moving Average、Cumulative Sum 1// Sibling聚合分析(min_bucket)2GET my_index/_search3&#123;4 \"size\": 0,5 \"aggs\":&#123;6 \"jobs\":&#123;7 \"terms\":&#123; // 根据job.keyword进行分桶8 \"field\":\"job.keyword\", 9 \"size\":1010 &#125;,11 \"aggs\":&#123;12 \"avg_salary\":&#123;13 \"avg\":&#123; // 之后Metric中求工资的平均数14 \"field\":\"salary\"15 &#125;16 &#125;17 &#125;18 &#125;,19 \"min_salary_by_job\":&#123;20 \"min_bucket\":&#123; // 关键词21 \"buckets_path\":\"jobs&gt;avg_salary\" // 按工资平均数，排列每个桶中的job22 &#125;23 &#125;24&#125; 1// Parent聚合分析(Derivate)2GET my_index/_search3&#123;4 \"size\":0,5 \"aggs\":&#123;6 \"bitrh\":&#123;7 \"date_histogram\":&#123;8 \"field\":\"birth\",9 \"interval\":\"year\",10 \"min_doc_count\":011 &#125;,12 \"aggs\":&#123;13 \"avg_salary\":&#123;14 \"avg\":&#123;15 \"field\":\"salary\"16 &#125;17 &#125;,18 \"derivative_avg_salary\":&#123;19 \"derivative\":&#123; // 关键词20 \"buckets_path\":\"avg_salary\"21 &#125;22 &#125;23 &#125;24 &#125;25 &#125;26&#125; 1.5 聚合分析的作用范围ES聚合分析默认作用范围是query的结果集 1// ES中聚合分析的默认作用范围是query的结果集2GET my_index/_search3&#123;4 \"size\":0,5 \"query\":&#123;6 \"match\":&#123;7 \"username\":\"alfred\"8 &#125;9 &#125;,10 \"aggs\":&#123;11 \"jobs\":&#123;12 \"terms\":&#123;13 \"match\":&#123; // 此时，只在username字段中包含alfred的文档中进行分桶14 \"field\":\"job.keyword\", 15 \"size\":1016 &#125;17 &#125;18 &#125;19 &#125;20&#125; 可通过以下方式修改：filter、post_filter、global filter: 为某个结合分析设定过滤条件，从而在不改变整体query语句的情况下修改范围 post_filter，作用于文档过滤，但在聚合分析之后才生效 global，无视query条件，基于所有文档进行分析 1// 使用filter进行过滤2GET my_index/_search3&#123;4 \"size\":0,5 \"aggs\":&#123;6 \"jobs_salary_small\":&#123;7 \"filter\":&#123;8 \"range\":&#123;9 \"salary\":&#123;10 \"to\":1000011 &#125;12 &#125;13 &#125;,14 \"aggs\":&#123;15 \"jobs\":&#123;16 \"terms\":&#123; // 在salary小于10000的文档中对工作进行分桶17 \"field\":\"job.keyword\"18 &#125;19 &#125;20 &#125;21 &#125;22 &#125;23&#125; 1// 使用post_filter进行过滤2GET my_index/_search3&#123;4 \"size\":0,5 \"aggs\":&#123;6 \"jobs\":&#123;7 \"terms\":&#123; // 在salary小于10000的文档中对工作进行分桶8 \"field\":\"job.keyword\"9 &#125;10 &#125;11 &#125;,12 \"post_filter\":&#123; // 在集合分析之后才生效13 \"match\":&#123;14 \"job.keyword\":\"java engineer\" 15 &#125;16 &#125;17&#125; 1// 使用global进行过滤2GET my_index/_search3&#123;4 \"query\":&#123;5 \"match\":&#123;6 \"job.keyword\":\"java engineer\"7 &#125;8 &#125;,9 \"aggs\":&#123;10 \"java_avg_salary\":&#123;11 \"avg\":&#123;12 \"field\":\"salary\"13 &#125;14 &#125;,15 \"all\":&#123;16 \"global\":&#123; // 关键词17 \"aggs\":&#123;18 \"avg_salary\":&#123;19 \"avg\":&#123;20 \"field\":\"salary\" // 依然是对所有的文档进行查询，而不会去管query 21 &#125;22 &#125;23 &#125;24 &#125;25 &#125;26 &#125;27&#125; 1.6 聚合分析中的排序 可使用自带的关键数据排序，如：_count文档数、_key按key值 也可使用聚合结果进行排序 1// 使用自带的数据进行排序2GET my_index/_search3&#123;4 \"size\":0,5 \"aggs\":&#123;6 \"jobs\":&#123;7 \"terms\":&#123;8 \"field\":\"job.keyword\",9 \"size\":10,10 \"order\":[11 &#123;12 \"_count\":\"asc\" // 默认按_count倒叙排列13 &#125;,14 &#123;15 \"_key\":\"desc\" 使用多个排序值，从上往下的顺序进行排列16 &#125;17 ]18 &#125;19 &#125;20 &#125;21&#125; 1// 使用聚合结果进行排序2GET my_index/_search3&#123;4 \"size\":0,5 \"aggs\":&#123;6 \"salary_hist\":&#123;7 \"histogram\":&#123;8 &#125;,9 \"aggs\":&#123;10 \"age\":&#123;11 \"filter\":&#123;12 \"range\":&#123;13 \"age\":&#123;14 \"gte\":1015 &#125;16 &#125;17 &#125;,18 \"aggs\":&#123;19 \"avg_age\":&#123;20 \"field\":\"age\"21 &#125;22 &#125; 23 &#125;24 &#125;25 &#125;26 &#125;27&#125; 1.7 计算精准度问题ES聚合的执行流程：每个Shard上分别计算，由coordinating Node做聚合。 Terms计算不准确原因：数据分散在多个Shard上，coordinating Node无法得悉数据全貌，那么在取数据的时候，造成精准度不准确。 如下图：正确结果应该为a,b,c,而返回的是a,b,d 解决办法有两种： 直接设置shard数量为1；消除数据分散问题，但无法承载大数据量。 设置shard_size大小，即每次从shard上额外多获取数据，从而提升精准度 terms聚合返回结果中有两个统计值： doc_count_error_upper_bound：被遗漏的term可能的最大值； sum_other_doc_count：返回结果bucket的term外其他term的文档总数。 设定show_term_doc_count_error可以查看每个bucket误算的最大值(doc_count_error_upper_bound,为0表示计算准确) Shard_Size默认大小：(size*1.5)+10 通过调整Shard_Size的大小降低doc_count_error_upper_bound来提升准确度 增大了整体的计算量，从而降低了响应时间 权衡 海量数据、精准度、实时性 三者只能取其二。 Elasticsearch目前支持两种近似算法：cardinality(度量) 和 percentiles(百分位数度量) 结果近似准确，但不一定精准 可通过参数的调整使其结果精准，但同时消耗更多时间和性能 2. ElasticSearch的数据建模数据建模(Data Modeling)大致分为三个阶段：概念建模、逻辑建模、物理建模 概念模型：时间占比10% 基础。确定系统的核心需求和范围边界，实际实体与实体之间的关系。 逻辑模型：时间占比60-70% 核心。确定系统的核心需求和范围边界，实际实体与实体之间的关系。 物理模型：时间占比20-30% 落地实现。结合具体的数据库产品，在满足业务读写性能等需求的前提下确定最终的定义。 2.1 ES中的数据建模ES是基于Luence以倒排索引为基础实现的存储体系，不遵循关系型数据库中的范式约定。 2.2 Mapping字段相关设置 enabled:true/false。false表示 仅存储，不做搜索或聚合分析。 **index:true/false。是否构建倒排索引。不需进行字段的检索的时候设为false。 index_options:docs/freqs/positions/offsets。确定存储倒排索引的哪些信息。 norms:true/false。是否存储归一化相关系数，若字段仅用于过滤和聚合分析，则可关闭。 doc_values:true/false。是否启用doc_values，用于排序和聚类分析。默认开启。 field_data:true/false。是否设text类型为fielddata，实现排序和聚合分析。默认关闭。 store:true/false。是否存储该字段。 coerce:true/false。 是否开启数值类型转换功能，如：字符串转数字等。 multifields:多字段。灵活使用多字段特性来解决多样业务需求。 dynamic:true/false/strict。控制mapping自动更新。 date_detection:true/false。是否启用自定识别日期类型，一般设为false，避免不必要的识别字符串中的日期。 2.3 Mapping字段属性设定流程判断类型—&gt;是否需要检索—&gt;是否需要排序和聚合分析—&gt;是否需要另行存储 判断类型 字符串类型：需要分词，则设为text，否则设为keyword。 枚举类型：基于性能考虑，设为keyword，即便该数据为整型。 数值类型：尽量选择贴近的类型，如byte即可表示所有数值时，即用byte，而不是所有都用long。 其他类型：布尔型，日期类型，地理位置类型等。 是否需要检索 完全不需要检索、排序、聚合分析的字段enabled设为false。 不需检索的字段index设为false。 需检索的字段，可通过如下配置设定需要的存储粒度: index_options 结合需要设定。 norms 不需归一化数据时可关闭。 是否需要排序和聚合分析 当不需要排序和聚合分析功能时： doc_values设为false。 field_data设为false。 是否需要另行存储 store设为true即可存储该字段的原始内容(且与_source无关)，一般结合_source的enabled设为false时使用。 2.4 ES建模实例 针对博客文章设定索引blog_index，包含字段： 标题：title 发布日期：publish_data 作者：author 摘要：abstract 网址：url 简易的数据模型： 1// 简易模型blog_index2PUT blog_index3&#123;4 \"mappings\":&#123;5 \"doc\":&#123;6 \"properties\":&#123;7 \"title\":&#123;8 //title设为text，包含自字段keyword。支持检索、排序、聚合分析9 \"type\":\"text\",10 \"fields\":&#123;11 \"keyword\":&#123;\"type\":\"keyword\"&#125;12 &#125;13 &#125;,//publish_data设为date，支持检索、排序、聚合分析14 \"publish_data\":&#123;\"type\":\"date\"&#125;,15 // author设为keyword，支持检索、排序、聚合分析16 \"author\":&#123;\"type\":\"keyword\"&#125;,17 // abstract设为text，支持检索、排序、聚合分析18 \"abstract\":&#123;\"type\":\"text\"&#125;,19 // url设为date，不需进行检索20 \"url\":&#123;\"enabled\":false&#125;21 &#125;22 &#125;23 &#125;24&#125; 如果在blog_index中加入一个内容字段content 1// 为blog_index增加content字段2PUT blog_index3&#123;4 \"mappings\":&#123;5 \"doc\":&#123;6 //关闭，不存原始内容到_source7 \"_source\":&#123;\"enabled\":false&#125;,8 \"properties\":&#123;9 //title设为text，包含自字段keyword。支持检索、排序、聚合分析10 \"title\":&#123;11 \"type\":\"text\",12 \"fields\":&#123;13 \"keyword\":&#123;14 \"type\":\"keyword\"15 &#125;16 &#125;,17 \"store\":true //对数据进行存储18 &#125;,//publish_data设为date，支持检索、排序、聚合分析19 \"publish_data\":&#123;20 \"type\":\"date\",21 \"store\":true // 对数据进行存储22 &#125;,23 \"author\":&#123;// author设为keyword，支持检索、排序、聚合分析24 \"type\":\"keyword\",25 \"store\":true // 对数据进行存储26 &#125;,27 \"abstract\":&#123;// abstract设为text，支持检索、排序、聚合分析28 \"type\":\"text\",29 \"store\":true // 对数据进行存储30 &#125;,31 \"content\":&#123;// content设为text，支持检索、排序、聚合分析32 \"type\":\"text\",33 \"store\":true // 对数据进行存储34 &#125;,35 \"url\":&#123;36 \"type\":\"keyword\", // url设为keyword37 \"doc_values\":false, // url不支持排序和聚合分析38 \"norms\":false, // url也不需要归一化数据39 \"ignore_above\":100, // 预设内容长度为10040 \"store\":true // 对数据进行存储41 &#125;42 &#125;43 &#125;44 &#125;45&#125; 在搜索时增加高亮: 在此时，content里面的数据会存储大量的内容数据，数据量可能达到上千、上万，甚至几十万。那么在搜索的时候，根据search机制，如果还是像之前一样进行_search搜索，并只显示其他字段的话，其实依然还是每次获取了content字段的内容，影响性能，所以，使用stored_fields参数，控制返回的字段。节省了大量资源： 1// 使用stored_fields返回指定的存储后的字段2GET blog_index/_search3&#123;4 \"stored_fields\":[\"title\",\"publish_data\",\"author\",\"Abstract\",\"url\"],5 \"query\":&#123;6 \"match\":&#123;7 \"content\":\"world\"//依然进行content搜索，但是不返回所有的content字段8 &#125;9 &#125;,10 \"highlight\":&#123; //针对content字段进行高亮显示11 \"fields\":&#123;12 \"content\":&#123;&#125;13 &#125;14 &#125;15&#125; 注意：GET blog_index/_search?_source=title 虽然只显示了title，但是search机制决定了，会把所有_source内容获取到，但只是显示title。 2.5 ES中关联关系处理ES不擅长处理关系型数据库中的关联关系，因为底层使用的倒排索引，如：文章表blog和评论表comment之间通过blog_id关联。目前ES主要有以下4种常用的方法来处理关联关系： Nested Object:嵌套文档 Parent/Child:父子文档 Data denormalization:数据的非规范化 Application-side joins:服务端Join或客户端Join 2.5.1 Application-side joins（服务端Join或客户端Join）索引之间完全独立（利于对数据进行标准化处理，如便于上述两种增量同步的实现），由应用端的多次查询来实现近似关联关系查询。 适用于第一个实体只有少量的文档记录的情况（使用ES的terms查询具有上限，默认1024，具体可在elasticsearch.yml中修改），并且最好它们很少改变。这将允许应用程序对结果进行缓存，并避免经常运行第一次查询。 2.5.2 Data denormalization（数据的非规范化）通俗点就是通过字段冗余，以一张大宽表来实现粗粒度的index，这样可以充分发挥扁平化的优势。但是这是以牺牲索引性能及灵活度为代价的。 使用的前提：冗余的字段应该是很少改变的；比较适合与一对少量关系的处理。当业务数据库并非采用非规范化设计时，这时要将数据同步到作为二级索引库的ES中，就很难使用上述增量同步方案，必须进行定制化开发，基于特定业务进行应用开发来处理join关联和实体拼接。 宽表处理在处理一对多、多对多关系时，会有字段冗余问题，适合“一对少量”且这个“一”更新不频繁的应用场景。 2.5.3 Nested objects（嵌套文档）索引性能和查询性能二者不可兼得，必须进行取舍。嵌套文档将实体关系嵌套组合在单文档内部（类似与json的一对多层级结构），这种方式牺牲索引性能（文档内任一属性变化都需要重新索引该文档）来换取查询性能，可以同时返回关系实体，比较适合于一对少量的关系处理。 当使用嵌套文档时，使用通用的查询方式是无法访问到的，必须使用合适的查询方式（nested query、nested filter、nested facet等），很多场景下，使用嵌套文档的复杂度在于索引阶段对关联关系的组织拼装。 2.5.4 Parent/Child（父子文档）父子文档牺牲了一定的查询性能来换取索引性能，适用于一对多的关系处理。其通过两种type的文档来表示父子实体，父子文档的索引是独立的。父-子文档ID映射存储在 Doc Values 中。当映射完全在内存中时， Doc Values 提供对映射的快速处理能力，另一方面当映射非常大时，可以通过溢出到磁盘提供足够的扩展能力。 在查询parent-child替代方案时，发现了一种filter-terms的语法，要求某一字段里有关联实体的ID列表。基本的原理是在terms的时候，对于多项取值，如果在另外的index或者type里已知主键id的情况下，某一字段有这些值，可以直接嵌套查询。具体可参考官方文档的示例：通过用户里的粉丝关系，微博和用户的关系，来查询某个用户的粉丝发表的微博列表。 父子文档相比嵌套文档较灵活，但只适用于“一对大量”且这个“一”不是海量的应用场景，该方式比较耗内存和CPU，这种方式查询比嵌套方式慢5~10倍，且需要使用特定的has_parent和has_child过滤器查询语法，查询结果不能同时返回父子文档（一次join查询只能返回一种类型的文档）。 而受限于父子文档必须在同一分片上，ES父子文档在滚动索引、多索引场景下对父子关系存储和联合查询支持得不好，而且子文档type删除比较麻烦（子文档删除必须提供父文档ID）。 如果业务端对查询性能要求很高的话，还是建议使用宽表化处理的方式，这样也可以比较好地应对聚合的需求。在索引阶段需要做join处理，查询阶段可能需要做去重处理，分页方式可能也得权衡考虑下。 2.6 ES中的reindexreindex：指重建所有数据的过程，一般发生在一下情况： mapping设置变更，如：字段类型变化，分词器字典更新等； index设置变更，如：分片数变化； 迁移数据。 ES提供了线程的api用于完成数据重建： _update_by_query：在现有索引上重建； _reindex：在其他索引上重建。 1// 将blog_index中所有文档重建一遍：2// 如果遇到版本冲突，依然执行。3POST blog_index/_update_by_query?conflicts=proceed 4// 此时如果blog_index中没有store的数据，则会报错 2.6.1 使用_update_by_query，更新文档的字段值和部分文档：1// 更新文档的字段值及部分文档2POST blog_index/_update_by_query3&#123;4 \"script\":&#123; // 更新文档的字段值5 \"source\":\"ctx._source.likes++\", // 代码6 \"lang\":\"painless\" // ES自带script语法7 &#125;,8 \"query\":&#123; // 更新部分文档9 \"term\":&#123;10 \"user\":\"tom\"11 &#125;12 &#125;13&#125; 在reindex发起后进入的文档，不会参与重建，类似于快照的机制。因此：一般在文档不再发生变更时，进行文档的reindex。 2.6.2 使用_reindex，重建数据：1// 使用_reindex：2POST _reindex3&#123;4 \"source\":&#123; // 被重建索引5 \"index\":\"blog_index\"6 &#125;,7 \"dest\":&#123; // 目标索引8 \"index\":\"blog_new_index\"9 &#125;10&#125; 数据重建时间，受到索引文档规模的影响，此时设定url参数wait_for_completion为false，来异步执行。 ES通过task来描述此类执行任务，并提供了task api来查看任务的执行进度和相关数据： 1// 使用task api2POST blog_index/_update_by_query?comflicts=proceed&amp;wait_for_completion=false3// 使用返回的taskid，查看任务的执行进度和相关数据4GET _tasks/&lt;返回的task id&gt; 2.7 其他建议： 对mapping进行版本管理： 要么写文件/注释，加入到Git仓库，一眼可见； 要么增加metadata字段，维护版本，并在每次更新mapping设置的时候加1。1\"metadata\":&#123;2 \"version\":13&#125; 防止字段过多： index.mapping.total_fields_limit，默认1000个。一般是因为没有高质量的数据建模导致，如：dynamic设为true。此时考虑查分多个索引来解决问题。","tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"https://wangyitao.github.io/tags/ElasticSearch/"},{"name":"Kibana","slug":"Kibana","permalink":"https://wangyitao.github.io/tags/Kibana/"},{"name":"ElasticStack","slug":"ElasticStack","permalink":"https://wangyitao.github.io/tags/ElasticStack/"},{"name":"LogStash","slug":"LogStash","permalink":"https://wangyitao.github.io/tags/LogStash/"}]}]